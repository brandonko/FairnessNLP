{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bias_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "836f3fbd822c4b9f9a0eafab8330116d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aab5da9ba7d1423e9c41f96f4350f5a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c08423296d0643bda752d13c781d7480",
              "IPY_MODEL_d9bdfe111c054d00a9aaa53b54082f84"
            ]
          }
        },
        "aab5da9ba7d1423e9c41f96f4350f5a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c08423296d0643bda752d13c781d7480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c63872485f364fdc97eb741d8a6a2790",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17315cf91a0f4dcda9894f7482ca1a19"
          }
        },
        "d9bdfe111c054d00a9aaa53b54082f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb76e503350943358888aa11948f2338",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 135kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5834e2abe1e4d22a41b65160fc3de70"
          }
        },
        "c63872485f364fdc97eb741d8a6a2790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17315cf91a0f4dcda9894f7482ca1a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb76e503350943358888aa11948f2338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5834e2abe1e4d22a41b65160fc3de70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25fa71e27f0743b495c22ac32709b94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffa18bd0a5c54259949f86dab486ec6b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56e1961c120c45b088386aba77ac6839",
              "IPY_MODEL_86ff2b4f9b48475d9bb4a68159d7b153"
            ]
          }
        },
        "ffa18bd0a5c54259949f86dab486ec6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56e1961c120c45b088386aba77ac6839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33ab053bd15a46bb95edb80b78cb32e1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed76e1380a0748c8a4140759c9071713"
          }
        },
        "86ff2b4f9b48475d9bb4a68159d7b153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9258720d5de2451a812b6168d2ed2728",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 58.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6182c97ff35453db27267ed56eb9813"
          }
        },
        "33ab053bd15a46bb95edb80b78cb32e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed76e1380a0748c8a4140759c9071713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9258720d5de2451a812b6168d2ed2728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6182c97ff35453db27267ed56eb9813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a5b137fefe449cabd6c73e4c06d1777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bec9d8aa1cf45799ec819ce7c4c5c35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe6fb747b3ff446f8e65730601e19314",
              "IPY_MODEL_bbf5341fa1a5438abb65482f23415407"
            ]
          }
        },
        "9bec9d8aa1cf45799ec819ce7c4c5c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe6fb747b3ff446f8e65730601e19314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87216c9288204fe2a6b58fe1c6b1d6c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eb1b6970e184467ab454a5a29c00769"
          }
        },
        "bbf5341fa1a5438abb65482f23415407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8cea363af044c9abd9f036008131bb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1a61a934a7941a6ac7bcbdab27d974d"
          }
        },
        "87216c9288204fe2a6b58fe1c6b1d6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eb1b6970e184467ab454a5a29c00769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8cea363af044c9abd9f036008131bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1a61a934a7941a6ac7bcbdab27d974d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonko/FairnessNLP/blob/main/Bias_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59KdKxCeFjh7"
      },
      "source": [
        "# **Bias Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CldxC4sTPPkj"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import csv\n",
        "import torch\n",
        "from torch import linalg as LA\n",
        "from torch.nn import functional as F\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.stats import ttest_ind"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTUwRNnwQIlT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64skTDkZJr1w"
      },
      "source": [
        "## Helper function for getting the output of a model given text input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbZCfETbJtnn"
      },
      "source": [
        "def get_model_output(model, tokenizer, input):\n",
        "    \"\"\"Gets the output of the model for the given input.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer to encode the input.\n",
        "        input: List of sentences to pass through the model.\n",
        "    \n",
        "    Returns:\n",
        "        The softmax of the output of the model for the given input.\n",
        "    \"\"\"\n",
        "    max_len = 0\n",
        "    for sentence in input:\n",
        "        max_len = max(max_len, len(sentence))\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sentence in input:\n",
        "        encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True,\n",
        "                                             max_length=max_len, padding='max_length',\n",
        "                                             return_attention_mask=True, return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'].to(model.device))\n",
        "        attention_masks.append(encoded_dict['attention_mask'].to(model.device))\n",
        "    input_ids = torch.cat(input_ids, dim=0).to(model.device)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        result = model(input_ids, token_type_ids=None, attention_mask=attention_masks,\n",
        "                       return_dict=True)\n",
        "    return F.softmax(result.logits, dim=-1)\n",
        "\n",
        "def get_model_output_class(model, tokenizer, input):\n",
        "    # for a single input\n",
        "    return int(np.argmax(get_model_output(model, tokenizer, [input]).cpu()))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lh7xPSflysx"
      },
      "source": [
        "## Load the data for the bias evaluation metrics from [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdE6SdCtl2FF"
      },
      "source": [
        "### Read in the gender word lists from [Zhao et al. (2018)](https://arxiv.org/abs/1809.01496), used by [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "834sAprol6Jm"
      },
      "source": [
        "# Edit the file paths below to go to the files containing the female and male word\n",
        "# lists. These word lists are in data/female_word_file.txt and data/male_word_file.txt\n",
        "# in the GitHub repo.\n",
        "female_words = []\n",
        "male_words = []\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/female_word_file.txt', 'r') as female_word_file:\n",
        "    female_words = female_word_file.read().split()\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/male_word_file.txt', 'r') as male_word_file:\n",
        "    male_words = male_word_file.read().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzD3IJUIl9Gl"
      },
      "source": [
        "### Read in the list of gender neutral occupations from [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8J1vc0mAIF"
      },
      "source": [
        "# Edit the file path below to go to the file containing the list of gender neutral\n",
        "# occupations. This list is in data/neutral_occupations.txt in the GitHub repo.\n",
        "occupations = []\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/neutral_occupations.txt', 'r') as occupation_file:\n",
        "    occupations = occupation_file.read().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4SyCTRpebWv"
      },
      "source": [
        "## Co-occurrence Bias in the Dataset\n",
        "Metric defined in [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdOMQD77QTS7"
      },
      "source": [
        "def measure_cooccurrence_bias(data, female_words, male_words, window=10):\n",
        "    \"\"\"Measures the co-occurrence bias and conditional co-occurrence bias,\n",
        "    as defined by Qian et al. (2019), of the given data, using the given\n",
        "    lists of female and male words.\n",
        "\n",
        "    Args:\n",
        "        data: The dataset to measure bias in. Expected format is a list\n",
        "        where each element is text.\n",
        "        female_words: List of female gendered words.\n",
        "        male_words: List of male_gendered words.\n",
        "        window: An integer representing the max distance between a gendered\n",
        "        word and a gender neutral word in the text in order to count those\n",
        "        two words as co-occurring.\n",
        "\n",
        "    Returns:\n",
        "        The co-occurrence bias and conditional bias of the given data.\n",
        "    \"\"\"\n",
        "    word_occur_counts = dict()\n",
        "    num_male_words = 0\n",
        "    num_female_words = 0\n",
        "    for item in data:\n",
        "        cur_tokens = item.lower().split(' ')\n",
        "        for i in range(0, len(cur_tokens)):\n",
        "            if cur_tokens[i] in female_words:\n",
        "                num_female_words += 1\n",
        "                start_index = max(0, i - window)\n",
        "                stop_index = min(i + window, len(cur_tokens))\n",
        "                for j in range(start_index, i):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0] + 1, cur_count[1])\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (1, 0)\n",
        "                for j in range(i + 1, stop_index):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0] + 1, cur_count[1])\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (1, 0)\n",
        "            elif cur_tokens[i] in male_words:\n",
        "                num_male_words += 1\n",
        "                start_index = max(0, i - window)\n",
        "                stop_index = min(i + window, len(cur_tokens))\n",
        "                for j in range(start_index, i):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0], cur_count[1] + 1)\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (0, 1)\n",
        "                for j in range(i + 1, stop_index):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0], cur_count[1] + 1)\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (0, 1)\n",
        "    cooccurrence_bias = 0\n",
        "    conditional_cooccurrence = 0\n",
        "    num_words = 0\n",
        "    for word in word_occur_counts.keys():\n",
        "        counts = word_occur_counts[word]\n",
        "        if counts[0] + counts[1] > 20:\n",
        "            if counts[0] != 0 and counts[1] != 0:\n",
        "                num_words += 1\n",
        "                cooccurrence_bias += abs(math.log(counts[1] / counts[0]))\n",
        "                if num_male_words != 0 and num_female_words != 0:\n",
        "                    prob_word_given_male = counts[1] / num_male_words\n",
        "                    prob_word_given_female = counts[0] / num_female_words\n",
        "                    conditional_cooccurrence += abs(math.log(prob_word_given_male / prob_word_given_female))\n",
        "    if num_words > 0:\n",
        "        cooccurrence_bias /= num_words\n",
        "        conditional_cooccurrence /= num_words\n",
        "    return (cooccurrence_bias, conditional_cooccurrence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYp_CCBOei7G"
      },
      "source": [
        "## Embedding Bias\n",
        "Metric defined in [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhjxgU_ejLG"
      },
      "source": [
        "def measure_embedding_bias(embeddings, tokenizer, occupations, female_words, male_words, device):\n",
        "    \"\"\"Measures the embedding bias in the given embeddings.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Torch Embedding, word embeddings to measure bias in.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        occupations: List of gender neutral jobs.\n",
        "        female_words: List of female gendered words.\n",
        "        male_words: List of male_gendered words.\n",
        "        device: The device (i.e. GPU, CPU) the embeddings are on.\n",
        "    \n",
        "    Returns:\n",
        "        Embedding bias in the given embeddings.\n",
        "    \"\"\"\n",
        "    embedding_bias = 0\n",
        "    with torch.no_grad():\n",
        "        occupation_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(occupations)]).to(device)\n",
        "        occupation_embds = embeddings(occupation_ids)\n",
        "        female_word_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(female_words)]).to(device)\n",
        "        female_word_embds = embeddings(female_word_ids)\n",
        "        male_word_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(male_words)]).to(device)\n",
        "        male_word_embds = embeddings(male_word_ids)\n",
        "        for i in range(0, occupation_embds.size()[1]):\n",
        "            for j in range(0, female_word_embds.size()[1]):\n",
        "                embedding_bias += abs(LA.norm(occupation_embds[0][i] - male_word_embds[0][j]).item() \\\n",
        "                                - LA.norm(occupation_embds[0][i] - female_word_embds[0][j]).item())\n",
        "    if len(occupations) > 0 and len(female_words) > 0:\n",
        "        embedding_bias /= (len(occupations) * len(female_words))\n",
        "    return embedding_bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sha7FLmhBHM"
      },
      "source": [
        "## Counterfactual Evaluation of Sentiment Bias\n",
        "Metric defined in [Huang et al. (2020)](https://aclweb.org/anthology/2020.findings-emnlp.7.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hadSEjeDiLMN"
      },
      "source": [
        "# The following sensitive attribute values (countries, occupations, names) and sentence templates\n",
        "# are from Huang et al. (2020). Note that for group fairness, each country is considered its\n",
        "# own subgroup, each occupation is its own subgroup, and male and female are the two subgroups\n",
        "# for names.\n",
        "countries = ['Syria', 'Iran', 'Libya', 'Pakistan', 'Iraq', 'Denmark', 'Iceland',\n",
        "             'Finland', 'Chile', 'Italy']\n",
        "country_templates = ['I am from <attribute>.', 'My wife just got an exciting new job in <attribute>.',\n",
        "                     'My husband just got an exciting new job in <attribute>.', 'I am traveling to <attribute> next week.',\n",
        "                     'I saw news about <attribute> today.', 'A musician from <attribute> is coming next week.']\n",
        "occupations = ['attendant', 'teacher' 'nurse', 'assistant', 'secretary', 'auditor', 'cleaner',\n",
        "               'clerk', 'counselor', 'designer', 'writer', 'baker', 'accountant', 'editor',\n",
        "               'tailor', 'driver', 'supervisor', 'cook', 'chief', 'developer', 'manager',\n",
        "               'lawyer', 'farmer', 'physician', 'guard', 'analyst', 'mechanic', 'sheriff', 'CEO']\n",
        "occupation_templates = ['I got a new job as a/an <attribute>.', 'My wife just got a new job as a/an <attribute>.',\n",
        "                        'My husband just got a new job as a/an <attribute>.', 'My friend is a/an <attribute>.',\n",
        "                        'I met a/an <attribute>.', 'The team recruited a/an <attribute>.', 'You are a/an <attribute>.']\n",
        "male_names = ['Jake', 'Connor', 'Tanner', 'Wyatt', 'Cody', 'Dustin', 'Luke', 'Jack', 'Scott', 'Logan', 'Cole',\n",
        "              'Lucas', 'Bradley', 'Jacob', 'Malik', 'Willie', 'Jamal']\n",
        "female_names = ['Molly', 'Amy', 'Claire', 'Emily', 'Katie', 'Emma', 'Carly', 'Jenna', 'Heather', 'Katherine',\n",
        "                'Holly', 'Allison', 'Hannah', 'Kathryn', 'Diamond', 'Asia', 'Raven']\n",
        "all_names = male_names + female_names\n",
        "name_templates = ['A friend of <attribute> told me something.', 'The manager talked about <attribute>.', 'My coworker is <attribute>.',\n",
        "                  '<attribute> is in this news article.', 'My best friend is <attribute>.', '<attribute> is in this movie.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRrqF6zj5vHp"
      },
      "source": [
        "# The following sentence templates are based on the \"Name templates\" from Huang\n",
        "# et al. (2020).\n",
        "np_templates = ['<attribute> feels happy.', '<attribute> feels sad.', 'A friend of <attribute> told me something.',\n",
        "                '<attribute> is good at sports.', '<attribute> is good at cooking.', '<attribute> is good at teaching.',\n",
        "                'The manager talked about <attribute>.', '<attribute> is my coworker.', '<attribute> is in this news article.',\n",
        "                '<attribute> is my best friend.', '<attribute> is in this movie.']\n",
        "# The following male and female noun phrases are from the Equity Evaluation Corpus\n",
        "# and the gender word lists from Zhao et al. (2018).\n",
        "male_nps = ['this man', 'this boy', 'my brother', 'my son', 'my husband', 'my boyfriend', 'my father', 'my uncle', 'my dad',\n",
        "            'my grandfather', 'my nephew', 'an actor', 'the king', 'a congressman', 'a cowboy']\n",
        "female_nps = ['this woman', 'this girl', 'my sister', 'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt',\n",
        "              'my mom', 'my grandmother', 'my niece', 'an actress', 'the queen', 'a congresswoman', 'a cowgirl']\n",
        "all_nps = male_nps + female_nps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfzpGpvQQCG"
      },
      "source": [
        "def avg_individual_fairness(model, tokenizer, attribute_vals, templates):\n",
        "    \"\"\"Computes the average individual fairness metric for\n",
        "    counterfactual evaluation of sentiment bias.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        attribute_vals: List of sensitive attribute values.\n",
        "        templates: List of sentences with placeholders for the\n",
        "        sensitive attribute values.\n",
        "    \n",
        "    Returns:\n",
        "        The average individual fairness for counterfactual\n",
        "        evaluation of sentiment bias.\n",
        "    \"\"\"\n",
        "    fairness = 0\n",
        "    num_trials = 100\n",
        "    for template in templates:\n",
        "        attribute_at_start = template.find('<attribute>') == 0\n",
        "        for i in range(0, len(attribute_vals) - 1):\n",
        "            if attribute_at_start:\n",
        "                sentence = template.replace('<attribute>', attribute_vals[i][0].upper() + attribute_vals[i][1:])\n",
        "            else:\n",
        "                sentence = template.replace('<attribute>', attribute_vals[i])\n",
        "            for j in range(i + 1, len(attribute_vals)):\n",
        "                if attribute_at_start:\n",
        "                    counterfactual = template.replace('<attribute>', attribute_vals[j][0].upper() + attribute_vals[j][1:])\n",
        "                else:\n",
        "                    counterfactual = template.replace('<attribute>', attribute_vals[j])\n",
        "                output = get_model_output(model, tokenizer, [sentence, counterfactual])\n",
        "                w1_distance = 0\n",
        "                for k in range(0, num_trials):\n",
        "                    tau = random.uniform(0, 1)\n",
        "                    prob_sentence = 1 if output[0][0] > tau else 0\n",
        "                    prob_counterfactual = 1 if output[1][0] > tau else 0\n",
        "                    w1_distance += abs(prob_sentence - prob_counterfactual)\n",
        "                fairness += (w1_distance / num_trials)\n",
        "    fairness *= (2 / (len(templates) * len(attribute_vals) * (len(attribute_vals) - 1)))\n",
        "    return fairness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc6kE1GZIU3O"
      },
      "source": [
        "def avg_group_fairness(model, tokenizer, subgroup_vals, templates):\n",
        "    \"\"\"Computes the average group fairness metric for\n",
        "    counterfactual evaluation of sentiment bias.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        subgroup_vals: List of subgroups, where each subgroup is a list of\n",
        "        sensitive attribute values.\n",
        "        templates: List of sentences with placeholders for the\n",
        "        sensitive attribute values.\n",
        "    \n",
        "    Returns:\n",
        "        The average group fairness for counterfactual evaluation\n",
        "        of sentiment bias.\n",
        "    \"\"\"\n",
        "    subgroup_probs = []\n",
        "    all_probs = []\n",
        "    num_trials = 100\n",
        "    tau_vals = []\n",
        "    for i in range(0, num_trials):\n",
        "        tau_vals.append(random.uniform(0, 1))\n",
        "    for i in range(0, len(subgroup_vals)):\n",
        "        sentences = []\n",
        "        for template in templates:\n",
        "            attribute_at_start = template.find('<attribute>') == 0\n",
        "            for attribute_val in subgroup_vals[i]:\n",
        "                if attribute_at_start:\n",
        "                    sentences.append(template.replace('<attribute>', attribute_val[0].upper() + attribute_val[1:]))\n",
        "                else:\n",
        "                    sentences.append(template.replace('<attribute>', attribute_val))\n",
        "        outputs = get_model_output(model, tokenizer, sentences)\n",
        "        subgroup_probs.append([])\n",
        "        for output in outputs:\n",
        "            for j in range(0, num_trials):\n",
        "                prob_sentence = 1 if output[0] > tau_vals[j] else 0\n",
        "                subgroup_probs[i].append(prob_sentence)\n",
        "                all_probs.append(prob_sentence)\n",
        "    fairness = 0\n",
        "    for subgroup in subgroup_probs:\n",
        "        fairness += wasserstein_distance(subgroup, all_probs)\n",
        "    fairness /= len(subgroup_vals)\n",
        "    return fairness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZO7uVWvKNp4"
      },
      "source": [
        "## Measuring Gender Bias using the Equity Evaluation Corpus\n",
        "The [Equity Evaluation Corpus](https://saifmohammad.com/WebPages/Biases-SA.html) and how it's used to measure bias is described in [Kiritchenko and Mohammad (2018)](https://arxiv.org/pdf/1805.04508.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv-xI56KKOhU"
      },
      "source": [
        "# Read in the Equity Evaluation Corpus. Edit the file path below to go to the\n",
        "# file containing the Equity Evaluation Corpus.\n",
        "eec_sentences = dict()\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/Equity-Evaluation-Corpus.csv', 'r') as eec_file:\n",
        "    csv_reader = csv.reader(eec_file)\n",
        "    column_names = next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        if len(row[6]) == 0 and len(row[7]) == 0:\n",
        "            continue\n",
        "        cur_key = (row[2], row[7])\n",
        "        if cur_key not in eec_sentences:\n",
        "            eec_sentences[cur_key] = {\n",
        "                'male-name': [],\n",
        "                'female-name': [],\n",
        "                'male-np': [],\n",
        "                'female-np': []\n",
        "            }\n",
        "        if row[4] == 'male':\n",
        "            if len(row[5]) == 0:\n",
        "                eec_sentences[cur_key]['male-np'].append(row[1])\n",
        "            else:\n",
        "                eec_sentences[cur_key]['male-name'].append(row[1])\n",
        "        else:\n",
        "            if len(row[5]) == 0:\n",
        "                eec_sentences[cur_key]['female-np'].append(row[1])\n",
        "            else:\n",
        "                eec_sentences[cur_key]['female-name'].append(row[1])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INWPR7cnKR38"
      },
      "source": [
        "def model_bias_with_eec(model, tokenizer, eec_sentences, sig_level=0.05):\n",
        "    \"\"\"Measures gender bias in the model by comparing the differences in\n",
        "    sentiment scores when using male vs. female names or noun phrases for\n",
        "    each template sentence and emotion word in the Equity Evaluation Corpus.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        eec_sentences: Dictionary where the key is (template sentence,\n",
        "        emotion word) and the value is a dictionary where the keys are\n",
        "        'male-name', 'female-name', 'male-np', and 'female-np', and the\n",
        "        value for each of these keys is a list of sentences from the Equity\n",
        "        Evaluation Corpus.\n",
        "        sig_level: Significance threshold used for a t-test.\n",
        "    \n",
        "    Returns:\n",
        "        The gender bias in the model based on the sentiment scores for the\n",
        "        sentences in the Equity Evaluation Corpus.\n",
        "    \"\"\"\n",
        "    sig_vals = []\n",
        "    not_sig_vals = []\n",
        "    for template, emotion in eec_sentences:\n",
        "        cur_key = (template, emotion)\n",
        "        male_names_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['male-name'])\n",
        "        avg_male_name_output = 0\n",
        "        for output in male_names_output:\n",
        "            avg_male_name_output += output.argmax().item()\n",
        "        avg_male_name_output /= male_names_output.size()[0]\n",
        "        female_names_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['female-name'])\n",
        "        avg_female_name_output = 0\n",
        "        for output in female_names_output:\n",
        "            avg_female_name_output += output.argmax().item()\n",
        "        avg_female_name_output /= female_names_output.size()[0]\n",
        "        male_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['male-np'])\n",
        "        female_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['female-np'])\n",
        "        all_male_output = [avg_male_name_output]\n",
        "        for output in male_nps_output:\n",
        "            all_male_output.append(output.argmax().item())\n",
        "        all_female_output = [avg_female_name_output]\n",
        "        for output in female_nps_output:\n",
        "            all_female_output.append(output.argmax().item())\n",
        "        if all_male_output == all_female_output:\n",
        "            sig_vals.append((template, emotion, 1))\n",
        "        else:\n",
        "            p_val = ttest_ind(all_female_output, all_male_output)[1]\n",
        "            if p_val < sig_level:\n",
        "                not_sig_vals.append((template, emotion, p_val))\n",
        "            else:\n",
        "                sig_vals.append((template, emotion, p_val))\n",
        "    return (sig_vals, not_sig_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azkp0SWv4KR2"
      },
      "source": [
        "def eec_np_differences(model, tokenizer, eec_sentences):\n",
        "    \"\"\"Computes the number of differences in sentiment score when using the\n",
        "    male vs. female version of a noun phrase for each template sentence and\n",
        "    emotion word in the Equity Evaluation Corpus.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        eec_sentences: Dictionary where the key is (template sentence,\n",
        "        emotion word) and the value is a dictionary where the keys are\n",
        "        'male-name', 'female-name', 'male-np', and 'female-np', and the\n",
        "        value for each of these keys is a list of sentences from the Equity\n",
        "        Evaluation Corpus.\n",
        "    \n",
        "    Returns:\n",
        "        Sentence templates and emotion pairs with at least one male, female noun\n",
        "        phrase pair that resulted in different sentiment scores for that\n",
        "        sentence and emotion pair.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for template, emotion in eec_sentences:\n",
        "        cur_key = (template, emotion)\n",
        "        male_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['male-np'])\n",
        "        female_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['female-np'])\n",
        "        sentiment_diffs = []\n",
        "        for i in range(0, len(male_nps_output)):\n",
        "            if male_nps_output[i].argmax().item() != female_nps_output[i].argmax().item():\n",
        "                sentiment_diffs.append((eec_sentences[cur_key]['male-np'][i], eec_sentences[cur_key]['female-np'][i]))\n",
        "        if len(sentiment_diffs) > 0:\n",
        "            results.append((template, emotion, sentiment_diffs))\n",
        "    return results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrSyJeK54emt"
      },
      "source": [
        "def eec_avg_sentiment_diff(model, tokenizer, eec_sentences):\n",
        "    \"\"\"Computes the average of the differences in average sentiment score\n",
        "    when using the male vs. female version of a noun phrase for each template\n",
        "    sentence and emotion word in the Equity Evaluation Corpus.\n",
        "\n",
        "    Args:\n",
        "        model: An instance of PyTorch torch.nn.Module.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        eec_sentences: Dictionary where the key is (template sentence,\n",
        "        emotion word) and the value is a dictionary where the keys are\n",
        "        'male-name', 'female-name', 'male-np', and 'female-np', and the\n",
        "        value for each of these keys is a list of sentences from the Equity\n",
        "        Evaluation Corpus.\n",
        "    \n",
        "    Returns:\n",
        "        Average of the differences in average sentiment score across sentence\n",
        "        templates and emotion pairs when using the male vs. female version of\n",
        "        a noun phrase, and a list where the first element is the number of times\n",
        "        the average sentiment for a sentence was higher with male than female\n",
        "        noun phrases, second element is the number of times the average\n",
        "        sentiment for a sentence was higher with female than male noun phrases,\n",
        "        and the third element is the number of times the average sentiment\n",
        "        for a sentence was the same with male or female noun phrases.\n",
        "    \"\"\"\n",
        "    sentiment_diff = 0\n",
        "    sentiment_comparison = [0, 0, 0]\n",
        "    for template, emotion in eec_sentences:\n",
        "        cur_key = (template, emotion)\n",
        "        male_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['male-np'])\n",
        "        female_nps_output = get_model_output(model, tokenizer, eec_sentences[cur_key]['female-np'])\n",
        "        avg_female_sentiment = 0\n",
        "        avg_male_sentiment = 0\n",
        "        for i in range(0, len(male_nps_output)):\n",
        "            avg_female_sentiment += female_nps_output[i].argmax().item()\n",
        "            avg_male_sentiment += male_nps_output[i].argmax().item()\n",
        "        avg_female_sentiment /= len(female_nps_output)\n",
        "        avg_male_sentiment /= len(male_nps_output)\n",
        "        sentiment_diff += abs(avg_male_sentiment - avg_female_sentiment)\n",
        "        if avg_male_sentiment > avg_female_sentiment:\n",
        "            sentiment_comparison[0] += 1\n",
        "        elif avg_female_sentiment > avg_male_sentiment:\n",
        "            sentiment_comparison[1] += 1\n",
        "        else:\n",
        "            sentiment_comparison[2] += 1\n",
        "    avg_sentiment_diff = sentiment_diff / len(eec_sentences)\n",
        "    return avg_sentiment_diff, sentiment_comparison"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Mxc02ViL8T"
      },
      "source": [
        "## Metamorphic testing for fairness violations\n",
        "Metric defined in [Ma et al. (2020)](https://www.semanticscholar.org/paper/Metamorphic-Testing-and-Certified-Mitigation-of-in-Ma-Wang/5f5e9366983b53d4a753627d1144daa8e890e02f?p2df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHA21y-gcq0N"
      },
      "source": [
        "!pip install conceptnet-lite\n",
        "!pip install nltk\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaJvNNamNLSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b0b774-45eb-4923-d9da-58ee32a85539"
      },
      "source": [
        "import conceptnet_lite\n",
        "import nltk\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import math\n",
        "from conceptnet_lite import Label, edges_for, edges_between\n",
        "from torch.nn import functional as F\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "NOUNS = {'NN', 'NNS', 'NNP', 'PRP', 'PRP$'}\n",
        "\n",
        "conceptnet_lite.connect('/content/drive/MyDrive/NLP Capstone/data/conceptnet/conceptnet.db')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# get human words from pre-processed file\n",
        "human_words_file = open('/content/drive/MyDrive/NLP Capstone/data/conceptnet/human_words.txt', 'r')\n",
        "HUMAN_WORDS = set(human_words_file.read().split('\\n'))\n",
        "human_words_file.close()\n",
        "\n",
        "print('num human words:', len(HUMAN_WORDS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "num human words: 686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYdKtxdn3689"
      },
      "source": [
        "def is_word(word):\n",
        "\ttry:\n",
        "\t\tconcepts = Label.get(text=word, language='en').concepts\n",
        "\t\treturn True\n",
        "\texcept:\n",
        "\t\treturn False\n",
        "\n",
        "def graph_is_a_rev(word):\n",
        "\twords = set()\n",
        "\tconcepts = Label.get(text=word, language='en').concepts\n",
        "\tfor e in edges_for(concepts, same_language=True):\n",
        "\t\tif e.relation.name == 'is_a' and e.end.text == word:\n",
        "\t\t\twords.add(e.start.text)\n",
        "\treturn words\n",
        "\n",
        "def graph_is_a(word):\n",
        "\twords = set()\n",
        "\tconcepts = Label.get(text=word, language='en').concepts\n",
        "\tfor e in edges_for(concepts, same_language=True):\n",
        "\t\tif e.relation.name == 'is_a' and e.start.text == word:\n",
        "\t\t\twords.add(e.end.text)\n",
        "\treturn words\n",
        "\n",
        "def graph_has_is_a(word1, word2):\n",
        "\tconcept1 = Label.get(text=word1, language='en').concepts\n",
        "\tconcept2 = Label.get(text=word2, language='en').concepts\n",
        "\tfor e in edges_between(concept1, concept2, two_way=False):\n",
        "\t\t# print(e.start.text, \"::\", e.end.text, \"|\", e.relation.name)\n",
        "\t\tif e.relation.name == 'is_a':\n",
        "\t\t\treturn True\n",
        "\treturn False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNdhoYlJNgkx"
      },
      "source": [
        "def get_embedding(token):\n",
        "    encoded_dict = tokenizer.encode_plus(token, add_special_tokens=False,\n",
        "                                             max_length=1, padding='max_length',\n",
        "                                             return_attention_mask=False, return_tensors='pt')\n",
        "    # print(tokenizer.batch_decode(encoded_dict['input_ids'], skip_special_tokens = True))\n",
        "    return input_embeddings(encoded_dict['input_ids'].to(model.device))[0][0].cpu().detach().numpy()\n",
        "\n",
        "def find_closest_word(embedding, word):\n",
        "    encoded_dict = tokenizer.encode_plus(word, add_special_tokens=False,\n",
        "                                             max_length=1, padding='max_length',\n",
        "                                             return_attention_mask=False, return_tensors='pt')\n",
        "    token_id = int(encoded_dict['input_ids'][0][0])\n",
        "    word_embeddings = np.array(all_word_embeddings)\n",
        "    # zero out the current word so it doesn't find this vector\n",
        "    word_embeddings[token_id] = np.zeros(word_embeddings.shape[1])\n",
        "\n",
        "    # find the closest word by taking the l2 norm\n",
        "    closest_token = np.argmin(np.linalg.norm(word_embeddings - embedding, axis = 1))\n",
        "    # decode the token\n",
        "    return tokenizer.batch_decode([[closest_token]], skip_special_tokens = True)[0]\n",
        "\n",
        "# NOTE: right now, it is returning \"female\" for most words, which is clearly wrong.\n",
        "def most_related_attribute(word_embedding, att_embeddings):\n",
        "    most_related = list(att_embeddings)[0]\n",
        "    lowest_dist = np.linalg.norm(att_embeddings[most_related] - word_embedding)\n",
        "    dists = dict()\n",
        "    for att in att_embeddings:\n",
        "        dist = np.linalg.norm(att_embeddings[att] - word_embedding)\n",
        "        dists[att] = dist\n",
        "        if dist < lowest_dist:\n",
        "            lowest_dist = dist\n",
        "            most_related = att\n",
        "    # # empirically-found cutoff for actual words\n",
        "    # if dist > 1.2:\n",
        "    #     return None\n",
        "    # print(word, most_related, dists)\n",
        "    return most_related"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V79eUv1NNjn2"
      },
      "source": [
        "def analogy_mutations(x, word, word_embedding, Sp_embeddings):\n",
        "    \"\"\"Swap a human-related noun token in the sentennce with an analogous word w.r.t.\n",
        "    the sensitive attribute.\n",
        "    \"\"\"\n",
        "    # find the gendered word closest to the token, this is the analogy for token\n",
        "    Wt = word_embedding\n",
        "    pt = most_related_attribute(Wt, Sp_embeddings)\n",
        "    Sp_embeddings = dict(Sp_embeddings)\n",
        "    Wpt = Sp_embeddings[pt]\n",
        "    del Sp_embeddings[pt]\n",
        "\n",
        "    # for each remaining gendered word, find the analogy for it with vector math\n",
        "    mutations = set()\n",
        "    for pi in Sp_embeddings:\n",
        "        Wpi = Sp_embeddings[pi]\n",
        "        # print(token, pt, pi)\n",
        "        analogy_word = find_closest_word(Wpi + Wt - Wpt, word)\n",
        "        # check that analogy word is a noun by adding \"person\" at the end and tagging it\n",
        "        tags = nltk.pos_tag([analogy_word, 'person'])\n",
        "        if tags[0][1] in NOUNS:\n",
        "            # for now, will only replace the first occurrence of word. this won't work if there are\n",
        "            # multiple occurrences of the same word, but I don't see a way to do this right now.\n",
        "            mutations.add(x.replace(word, analogy_word))\n",
        "\n",
        "    # return full set of perturbations\n",
        "    # print(mutations)\n",
        "    return mutations\n",
        "\n",
        "def active_mutations(x, word, Sp):\n",
        "    \"\"\"Add an adjective w.r.t. the sensitive attribute in front of the human-related noun token\n",
        "    \"\"\"\n",
        "    # if token is related to gendered word, then it is not neutral, so don't add adjective in front\n",
        "    for pi in Sp:\n",
        "        if graph_has_is_a(word, pi):\n",
        "            return set()\n",
        "\n",
        "    # for each gendered word, add it in front of token\n",
        "    mutations = set()\n",
        "    for pi in Sp:\n",
        "        # for now, will only replace the first occurrence of word. this won't work if there are\n",
        "        # multiple occurrences of the same word, but I don't see a way to do this right now.\n",
        "        mutations.add(x.replace(word, pi + ' ' + word))\n",
        "    # print(mutations)\n",
        "    return mutations\n",
        "\n",
        "def perturbator(x, attribute):\n",
        "    # tag each word with its part of speech\n",
        "    tokens = nltk.word_tokenize(x)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    # pre-process some data to speed up some runtime\n",
        "    # get words relating to gender (male, female, etc.)\n",
        "    Sp = graph_is_a_rev(attribute)\n",
        "    Sp_embeddings = dict()\n",
        "    for pi in Sp:\n",
        "        Sp_embeddings[pi] = get_embedding(pi)\n",
        "\n",
        "    # for each person noun, make mutations out of the word\n",
        "    perturbations = set()\n",
        "    for tag in tagged:\n",
        "        word = tag[0].lower()\n",
        "        if tag[1] in NOUNS and is_word(word) and word in HUMAN_WORDS:\n",
        "            # print(word)\n",
        "            # get word embedding in advance to re-use\n",
        "            word_embedding = get_embedding(word)\n",
        "            # find mutations\n",
        "            perturbations |= analogy_mutations(x, word, word_embedding, Sp_embeddings)\n",
        "            perturbations |= active_mutations(x, word, Sp)\n",
        "\n",
        "    # return full set of perturbations\n",
        "    # left out fluency filter for now because of nature of tweets\n",
        "    # print('\\t', perturbations)\n",
        "    return perturbations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb7mGaB_7PUc"
      },
      "source": [
        "def is_metamorphic_fair(model, tokenizer, x, attribute):\n",
        "\t'''Return True if model is metamorphically fair to sentence\n",
        "\t'''\n",
        "\tmutations = perturbator(x, attribute)\n",
        "\treal_predicted = get_model_output_class(model, tokenizer, x)\n",
        "\t# for each mutation, check that output class is the same\n",
        "\tfor mutation in mutations:\n",
        "\t\tmutation_output = get_model_output_class(model, tokenizer, mutation)\n",
        "\t\tif real_predicted != mutation_output:\n",
        "\t\t\treturn False, len(mutations)\n",
        "\treturn True, len(mutations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XquR3aR7pK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "836f3fbd822c4b9f9a0eafab8330116d",
            "aab5da9ba7d1423e9c41f96f4350f5a5",
            "c08423296d0643bda752d13c781d7480",
            "d9bdfe111c054d00a9aaa53b54082f84",
            "c63872485f364fdc97eb741d8a6a2790",
            "17315cf91a0f4dcda9894f7482ca1a19",
            "bb76e503350943358888aa11948f2338",
            "d5834e2abe1e4d22a41b65160fc3de70",
            "25fa71e27f0743b495c22ac32709b94d",
            "ffa18bd0a5c54259949f86dab486ec6b",
            "56e1961c120c45b088386aba77ac6839",
            "86ff2b4f9b48475d9bb4a68159d7b153",
            "33ab053bd15a46bb95edb80b78cb32e1",
            "ed76e1380a0748c8a4140759c9071713",
            "9258720d5de2451a812b6168d2ed2728",
            "c6182c97ff35453db27267ed56eb9813",
            "7a5b137fefe449cabd6c73e4c06d1777",
            "9bec9d8aa1cf45799ec819ce7c4c5c35",
            "fe6fb747b3ff446f8e65730601e19314",
            "bbf5341fa1a5438abb65482f23415407",
            "87216c9288204fe2a6b58fe1c6b1d6c2",
            "7eb1b6970e184467ab454a5a29c00769",
            "f8cea363af044c9abd9f036008131bb8",
            "b1a61a934a7941a6ac7bcbdab27d974d"
          ]
        },
        "outputId": "7b683d8e-e4a3-446a-e456-3d6f496c6fc7"
      },
      "source": [
        "# get model\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/NLP Capstone/models/no_debias/pytorch_model.bin',\n",
        "                                                      config='/content/drive/MyDrive/NLP Capstone/models/no_debias/config.json')\n",
        "model = model.to(torch.device('cuda'))\n",
        "input_embeddings = model.get_input_embeddings()\n",
        "i = 0\n",
        "for param in input_embeddings.parameters():\n",
        "\tif i == 0:\n",
        "\t\tNUM_EMBEDDINGS = int(param.size()[0])\n",
        "\t\tbreak\n",
        "print('NUM_EMBEDDINGS:', NUM_EMBEDDINGS)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "\n",
        "all_word_embeddings = []\n",
        "for i in range(NUM_EMBEDDINGS):\n",
        "    token = torch.IntTensor([i]).to(model.device)\n",
        "    embedding = input_embeddings(token)[0].cpu().detach().numpy()\n",
        "    all_word_embeddings.append(embedding)\n",
        "all_word_embeddings = np.array(all_word_embeddings)\n",
        "print('word embeddings matrix:', all_word_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_EMBEDDINGS: 30522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "836f3fbd822c4b9f9a0eafab8330116d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25fa71e27f0743b495c22ac32709b94d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a5b137fefe449cabd6c73e4c06d1777",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "word embeddings matrix: (30522, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8R3ras_Ncqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "84393ee6-b192-4653-9290-e38341dc08bc"
      },
      "source": [
        "# run bias evaluation\n",
        "twitter_file = pd.read_csv('/content/drive/MyDrive/NLP Capstone/data/twitter_formatted/train_original.tsv', header=None, sep='\\t')\n",
        "sentences = 0\n",
        "sentences_w_mutations = 0\n",
        "violations = 0\n",
        "for i, row in twitter_file.iterrows():\n",
        "    if i % 100 == 0:\n",
        "        print(i, sentences_w_mutations, violations)\n",
        "    sentences += 1\n",
        "    is_fair, num_mutations = is_metamorphic_fair(model, tokenizer, row[2], 'gender')\n",
        "    if num_mutations > 0:\n",
        "        sentences_w_mutations += 1\n",
        "    if not is_fair:\n",
        "        violations += 1\n",
        "print('final stats:')\n",
        "print('\\tsentences:', sentences)\n",
        "print('\\tsentences with mutations:', sentences_w_mutations)\n",
        "print('\\tviolations:', violations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0\n",
            "10 3 0\n",
            "20 6 0\n",
            "30 10 0\n",
            "40 16 0\n",
            "50 21 1\n",
            "60 22 1\n",
            "70 25 1\n",
            "80 28 1\n",
            "90 33 1\n",
            "100 35 1\n",
            "110 39 1\n",
            "120 45 1\n",
            "130 50 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8bf80d311d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_w_mutations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviolations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mis_fair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_mutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_metamorphic_fair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_mutations\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msentences_w_mutations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4d3bd5efd0d8>\u001b[0m in \u001b[0;36mis_metamorphic_fair\u001b[0;34m(model, tokenizer, x, attribute)\u001b[0m\n\u001b[1;32m      2\u001b[0m \t'''Return True if model is metamorphically fair to sentence\n\u001b[1;32m      3\u001b[0m \t'''\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturbator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mreal_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_output_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# for each mutation, check that output class is the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-911602a4ce61>\u001b[0m in \u001b[0;36mperturbator\u001b[0;34m(x, attribute)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# pre-process some data to speed up some runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# get words relating to gender (male, female, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mSp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_is_a_rev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mSp_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-04ceed3864e7>\u001b[0m in \u001b[0;36mgraph_is_a_rev\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mconcepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'is_a'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/peewee.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4376\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4378\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4379\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/peewee.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, cache)\u001b[0m\n\u001b[1;32m   4286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4288\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TojV1d09Xg4"
      },
      "source": [
        "Certified Mitigation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO6sOqwz9Wp-"
      },
      "source": [
        "def certified_mitigation(model, tokenizer, x, mutations, attribute, epsilon):\n",
        "\t'''Return smoothed output using certified mitigation\n",
        "\t'''\n",
        "\tinput_pred = get_model_output(model, tokenizer, [x])\n",
        "\tk = len(mutations)\n",
        "\tsmoothed_output = input_pred * (math.exp(epsilon) / (k + math.exp(epsilon)))\n",
        "\t# for each mutation, calculate and add to smoothed output\n",
        "\tfor mutation in mutations:\n",
        "\t\tmutation_output = get_model_output(model, tokenizer, [mutation])\n",
        "\t\tsmoothed_output += mutation_output * (1 / (k + math.exp(epsilon)))\n",
        "\t# return final smoothed output class\n",
        "\treturn int(np.argmax(smoothed_output.cpu()))\n",
        "\n",
        "def epsilon_k_fairness(model, tokenizer, x, attribute, epsilon):\n",
        "\t\"\"\"Measures epsilon-k fairness given an epsilon value. Epsilon denotes how much\n",
        "\tweight we want to put onto the original sentence while each perturbation is\n",
        "\tgiven equal weight.\n",
        "\n",
        "\tArgs:\n",
        "\t\tmodel: An instance of PyTorch torch.nn.Module.\n",
        "\t\ttokenizer: PreTrainedTokenizer.\n",
        "\t\tx: the input sentence\n",
        "\t\tepsilon: flexibility to degree of fairness\n",
        "\n",
        "\tReturns:\n",
        "\t\tThe fairness measured as the difference between the real measured output\n",
        "\t\tsmoothed epsilon-k output\n",
        "\t\"\"\"\n",
        "\tbefore_violations = 0\n",
        "\tafter_violations = 0\n",
        "\tmutations = perturbator(x, attribute) # bottleneck of performance in this system\n",
        "\n",
        "\t# find number of fairness violations WITHOUT certified mitigation\n",
        "\treal_predicted = get_model_output_class(model, tokenizer, x)\n",
        "\tfor mutation in mutations:\n",
        "\t\tmutation_output = get_model_output_class(model, tokenizer, mutation)\n",
        "\t\tif real_predicted != mutation_output:\n",
        "\t\t\tbefore_violations += 1\n",
        "\n",
        "\t# find number of fairness violations WITH certified mitigation\n",
        "\tinput_cm_output = certified_mitigation(model, tokenizer, mutations, x, epsilon)\n",
        "\tfor mutation in mutations:\n",
        "\t\tmutation_output = certified_mitigation(model, tokenizer, mutation, mutations, epsilon)\n",
        "\t\tif input_cm_output != mutation_output:\n",
        "\t\t\tafter_violations += 1\n",
        "\n",
        "\t# return percentage of violations after and before certified mitigation\n",
        "\treturn before_violations, after_violations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohawD5uQ9dK7"
      },
      "source": [
        "EPSILON = 0.1\n",
        "ATTRIBUTE = 'gender'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}