{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bias_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/brandonko/FairnessNLP/blob/main/Bias_Evaluation.ipynb",
      "authorship_tag": "ABX9TyOQJzG8FyclK5CR8r5BDjpt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonko/FairnessNLP/blob/main/Bias_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59KdKxCeFjh7"
      },
      "source": [
        "# **Bias Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CldxC4sTPPkj"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import linalg as LA"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lh7xPSflysx"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdE6SdCtl2FF"
      },
      "source": [
        "### Read in the gender word lists from [Zhao et al. (2018)](https://arxiv.org/abs/1809.01496), used by [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "834sAprol6Jm"
      },
      "source": [
        "# Edit the file paths below to go to the files containing the female and male word\n",
        "# lists. These word lists are in data/female_word_file.txt and data/male_word_file.txt\n",
        "# in the GitHub repo.\n",
        "female_words = []\n",
        "male_words = []\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/female_word_file.txt', 'r') as female_word_file:\n",
        "    female_words = female_word_file.read().split()\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/male_word_file.txt', 'r') as male_word_file:\n",
        "    male_words = male_word_file.read().split()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzD3IJUIl9Gl"
      },
      "source": [
        "### Read in the list of gender neutral occupations from [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8J1vc0mAIF"
      },
      "source": [
        "# Edit the file path below to go to the file containing the list of gender neutral\n",
        "# occupations. This list is in data/neutral_occupations.txt in the GitHub repo.\n",
        "occupations = []\n",
        "with open('/content/drive/MyDrive/NLP Capstone/data/neutral_occupations.txt', 'r') as occupation_file:\n",
        "    occupations = occupation_file.read().split()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4SyCTRpebWv"
      },
      "source": [
        "## Co-occurrence Bias in the Dataset\n",
        "Metric defined in [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdOMQD77QTS7"
      },
      "source": [
        "def measure_cooccurrence_bias(data, female_words, male_words, window=10):\n",
        "    \"\"\"Measures the co-occurrence bias and conditional co-occurrence bias,\n",
        "    as defined by Qian et al. (2019), of the given data, using the given\n",
        "    lists of female and male words.\n",
        "\n",
        "    Args:\n",
        "        data: The dataset to measure bias in. Expected format is a list\n",
        "        where each element is text.\n",
        "        female_words: List of female gendered words.\n",
        "        male_words: List of male_gendered words.\n",
        "        window: An integer representing the max distance between a gendered\n",
        "        word and a gender neutral word in the text in order to count those\n",
        "        two words as co-occurring.\n",
        "\n",
        "    Returns:\n",
        "        The co-occurrence bias and conditional bias of the given data.\n",
        "    \"\"\"\n",
        "    word_occur_counts = dict()\n",
        "    num_male_words = 0\n",
        "    num_female_words = 0\n",
        "    for item in data:\n",
        "        cur_tokens = item.lower().split(' ')\n",
        "        for i in range(0, len(cur_tokens)):\n",
        "            if cur_tokens[i] in female_words:\n",
        "                num_female_words += 1\n",
        "                start_index = max(0, i - window)\n",
        "                stop_index = min(i + window, len(cur_tokens))\n",
        "                for j in range(start_index, i):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0] + 1, cur_count[1])\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (1, 0)\n",
        "                for j in range(i + 1, stop_index):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0] + 1, cur_count[1])\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (1, 0)\n",
        "            elif cur_tokens[i] in male_words:\n",
        "                num_male_words += 1\n",
        "                start_index = max(0, i - window)\n",
        "                stop_index = min(i + window, len(cur_tokens))\n",
        "                for j in range(start_index, i):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0], cur_count[1] + 1)\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (0, 1)\n",
        "                for j in range(i + 1, stop_index):\n",
        "                    if (cur_tokens[j] not in female_words) and (cur_tokens[j] not in male_words):\n",
        "                        if cur_tokens[j] in word_occur_counts:\n",
        "                            cur_count = word_occur_counts[cur_tokens[j]]\n",
        "                            word_occur_counts[cur_tokens[j]] = (cur_count[0], cur_count[1] + 1)\n",
        "                        else:\n",
        "                            word_occur_counts[cur_tokens[j]] = (0, 1)\n",
        "    cooccurrence_bias = 0\n",
        "    conditional_cooccurrence = 0\n",
        "    num_words = 0\n",
        "    for word in word_occur_counts.keys():\n",
        "        counts = word_occur_counts[word]\n",
        "        if counts[0] + counts[1] > 20:\n",
        "            if counts[0] != 0 and counts[1] != 0:\n",
        "                num_words += 1\n",
        "                cooccurrence_bias += abs(math.log(counts[1] / counts[0]))\n",
        "                if num_male_words != 0 and num_female_words != 0:\n",
        "                    prob_word_given_male = counts[1] / num_male_words\n",
        "                    prob_word_given_female = counts[0] / num_female_words\n",
        "                    conditional_cooccurrence += abs(math.log(prob_word_given_male / prob_word_given_female))\n",
        "    if num_words > 0:\n",
        "        cooccurrence_bias /= num_words\n",
        "        conditional_cooccurrence /= num_words\n",
        "    return (cooccurrence_bias, conditional_cooccurrence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYp_CCBOei7G"
      },
      "source": [
        "## Embedding Bias\n",
        "Metric defined in [Qian et al. (2019)](https://arxiv.org/pdf/1905.12801.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHhjxgU_ejLG"
      },
      "source": [
        "def measure_embedding_bias(embeddings, tokenizer, occupations, female_words, male_words):\n",
        "    \"\"\"Measures the embedding bias in the given embeddings.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Torch Embedding, word embeddings to measure bias in.\n",
        "        tokenizer: PreTrainedTokenizer.\n",
        "        occupations: List of gender neutral jobs.\n",
        "        female_words: List of female gendered words.\n",
        "        male_words: List of male_gendered words.\n",
        "    \n",
        "    Returns:\n",
        "        Embedding bias in the given embeddings.\n",
        "    \"\"\"\n",
        "    embedding_bias = 0\n",
        "    with torch.no_grad():\n",
        "        occupation_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(occupations)])\n",
        "        occupation_embds = embeddings(occupation_ids)\n",
        "        female_word_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(female_words)])\n",
        "        female_word_embds = embeddings(female_word_ids)\n",
        "        male_word_ids = torch.LongTensor([tokenizer.convert_tokens_to_ids(male_words)])\n",
        "        male_word_embds = embeddings(male_word_ids)\n",
        "        for i in range(0, occupation_embds.size()[1]):\n",
        "            for j in range(0, female_word_embds.size()[1]):\n",
        "                embedding_bias += abs(LA.norm(occupation_embds[0][i] - male_word_embds[0][j]).item() \\\n",
        "                                - LA.norm(occupation_embds[0][i] - female_word_embds[0][j]).item())\n",
        "    return embedding_bias"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sha7FLmhBHM"
      },
      "source": [
        "## Counterfactual Evaluation of Sentiment Bias\n",
        "Metric defined in [Huang et al. (2020)](https://aclweb.org/anthology/2020.findings-emnlp.7.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hadSEjeDiLMN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Mxc02ViL8T"
      },
      "source": [
        "## (epsilon-k)-Fairness\n",
        "Metric defined in [Ma et al. (2020)](https://www.semanticscholar.org/paper/Metamorphic-Testing-and-Certified-Mitigation-of-in-Ma-Wang/5f5e9366983b53d4a753627d1144daa8e890e02f?p2df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U40e-zQizwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}